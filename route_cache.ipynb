{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = pd.read_csv('./input/synthetic_data_100000.csv',usecols=['lon','lat','uid','time'])\n",
    "traj = traj[traj['uid']==0]\n",
    "traj.sort_values(by=['uid','time'],inplace=True)\n",
    "traj = traj.dropna()\n",
    "start_time = pd.to_datetime('2023-07-12')\n",
    "traj['time'] = pd.to_datetime(traj['time'])\n",
    "traj = traj[traj['time']>=start_time]\n",
    "traj['timestamp'] = (traj['time'] - start_time).dt.total_seconds()/60\n",
    "traj = traj[~((traj['timestamp']%(24*60)==0)&(traj['timestamp']/(24*60)>0))]\n",
    "traj['elat'] = traj.groupby('uid')['lat'].shift(-1)\n",
    "traj['elon'] = traj.groupby('uid')['lon'].shift(-1)\n",
    "traj = traj.dropna()\n",
    "traj['traj'] = traj.apply(lambda x: str(x['lon'])+str(x['lat'])+str(x['elon'])+str(x['elat']),axis=1)\n",
    "traj.drop_duplicates(subset=['traj','uid'],keep='first',inplace=True)\n",
    "traj.drop(columns=['traj'],inplace=True)\n",
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def generate_unique_key(slon, slat, elon, elat):\n",
    "    coordinates_str = f\"{slon},{slat},{elon},{elat}\"\n",
    "    return hashlib.md5(coordinates_str.encode('utf-8')).hexdigest()\n",
    "traj['md5'] = traj.apply(lambda x: generate_unique_key(x['lon'],x['lat'],x['elon'],x['elat']),axis=1)\n",
    "traj['index'] = [i for i in range(len(traj))]\n",
    "route_list = [0 for i in range(len(traj))]\n",
    "route_index_dict = {row['md5']:row['index'] for _ , row in traj.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "G = ox.load_graphml('./data/shanghai_road.graphml')\n",
    "hwy_speeds={\"residential\": 35, \"secondary\": 50,\n",
    "                    'primary': 50, \"tertiary\": 60}\n",
    " # 设置路网\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)  # 将路网转换为GeoDataFrame\n",
    "# 连接两个节点只保留一条边\n",
    "gdf_edges = gdf_edges.reset_index().drop_duplicates(\n",
    "    subset=['u', 'v'], keep='first')\n",
    "gdf_edges['key'] = 0\n",
    "gdf_edges = gdf_edges.set_index(['u', 'v', 'key'])\n",
    "# 重新构建路网\n",
    "# 图属性,这里使用了之前的路网数据的图属性\n",
    "G = ox.graph_from_gdfs(gdf_nodes, gdf_edges, graph_attrs=G.graph)\n",
    "# 路网最大强连通子图\n",
    "G = ox.utils_graph.get_largest_component(G,\n",
    "                                            strongly=True  # 是否强连通\n",
    "                                            )\n",
    "# 计算每条边出行时长\n",
    "G = ox.add_edge_speeds(G, hwy_speeds)\n",
    "G = ox.add_edge_travel_times(G)\n",
    "\n",
    "import numpy as np\n",
    "def find_travel_path(G, slon, slat, elon, elat, md5 , shortest=1, weight='travel_time'):\n",
    "    # 找到两点间的最短出行路径\n",
    "    # 由给定的坐标获取最近节点\n",
    "    orig = ox.distance.nearest_nodes(G, X=slon, Y=slat)\n",
    "    dest = ox.distance.nearest_nodes(G, X=elon, Y=elat)\n",
    "    if shortest == 1:\n",
    "        # 找到最短路径\n",
    "        travel_route = ox.shortest_path(\n",
    "            G, orig, dest, weight=weight)\n",
    "    if shortest > 1:\n",
    "        # 前k最短路径中选择一个\n",
    "        routes = ox.k_shortest_paths(\n",
    "            G, orig, dest, k=shortest, weight=weight)\n",
    "        routes = list(routes)\n",
    "        travel_route = routes[np.random.choice(range(len(routes)))]\n",
    "    # 获取路径上的行驶时间\n",
    "    travel_time = ox.utils_graph.get_route_edge_attributes(\n",
    "        G, travel_route, attribute='travel_time')\n",
    "    length = ox.utils_graph.get_route_edge_attributes(\n",
    "        G, travel_route, attribute='length')\n",
    "    # 将路径和行驶时间组合成字典\n",
    "    route = {\n",
    "        'travel_route': travel_route,\n",
    "        'travel_time': travel_time,\n",
    "        'length': length,\n",
    "        'has_path': len(travel_route) > 1,\n",
    "        'md5': md5}\n",
    "    route_list[route_index_dict[md5]] = route\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.apply(lambda row: find_travel_path(G,row['lon'],row['lat'],row['elon'],row['elat'],row['md5']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "def save_cache_file(cache_dir, route_list, route_index_dict):\n",
    "    route_json = json.dumps(route_list)\n",
    "    route_index_json = json.dumps(route_index_dict)\n",
    "    with open(cache_dir+'route_cache.pkl','wb') as file:\n",
    "        pickle.dump(route_json, file)\n",
    "    with open(cache_dir+'route_index_cache.pkl','wb') as file:\n",
    "        pickle.dump(route_index_json,file)\n",
    "save_cache_file('./cache/',route_list,route_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267195120"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
